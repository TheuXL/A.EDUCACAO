from typing import List, Dict, Any, Optional, Tuple, Set
import re
from pathlib import Path
from datetime import datetime
import os

from backend.app.domain.entities.document import Document, DocumentType
from backend.app.domain.interfaces.prompt_service import PromptService
from backend.app.domain.interfaces.search_service import SearchService
from backend.app.domain.interfaces.user_progress_repository import UserProgressRepository
from backend.app.domain.entities.user_progress import UserProgress, UserInteraction
from backend.app.infrastructure.repositories.json_user_progress_repository import JsonUserProgressRepository


class PromptServiceImpl(PromptService):
    """
    Implementa√ß√£o do servi√ßo de gera√ß√£o de respostas adaptativas.
    Utiliza o SearchService para encontrar documentos relevantes e gera
    respostas personalizadas com base no perfil do usu√°rio.
    """
    
    # Dicion√°rio de expans√£o de termos para enriquecer as consultas
    QUERY_EXPANSION = {
          "html5": ["html", "web", "markup", "tags", "estrutura"],
    "estrutura": ["html5", "html", "web", "markup", "sem√¢ntica"],
    "navegador": ["browser", "chrome", "firefox", "web", "html"],
    "p√°ginas": ["html5", "web", "interface", "documento"],
    "tags": ["html", "html5", "markup", "elemento", "estrutura"],
    "elementos": ["tag", "html", "html5", "web"],
    "lista": ["ordenada", "n√£o ordenada", "html", "markup"],
    "tabela": ["html", "markup", "web", "dados"],
    "link": ["html", "navega√ß√£o", "url", "web"],
    "figura": ["imagem", "media", "html", "web"],
    "conte√∫do": ["informa√ß√£o", "dados", "p√°gina", "html"],
    "cria√ß√£o": ["markup", "estrutura", "web"],
    "texto": ["par√°grafo", "html", "documento", "markup"]
    }
    
    def __init__(
        self, 
        search_service: SearchService,
        user_progress_repository: Optional[UserProgressRepository] = None
    ):
        """
        Inicializa o servi√ßo de prompt.
        
        Args:
            search_service: Servi√ßo de busca para encontrar documentos relevantes
            user_progress_repository: Reposit√≥rio para armazenamento do progresso do usu√°rio.
                                     Se None, utiliza JsonUserProgressRepository.
        """
        self.search_service = search_service
        
        # Se n√£o for fornecido um reposit√≥rio, usa o JsonUserProgressRepository
        if user_progress_repository is None:
            self.user_progress_repository = JsonUserProgressRepository()
        else:
            self.user_progress_repository = user_progress_repository
            
        # Manter contexto da sess√£o
        self.session_context = {}
        
        # Diret√≥rio base
        base_dir = Path(os.path.abspath(os.path.join(
            os.path.dirname(__file__), 
            "..", "..", "..", ".."
        )))
        
        # Diret√≥rio de recursos processados
        self.resources_dir = base_dir / "processed_data"
        
        # Verifica se h√° recursos dispon√≠veis
        self.available_resources = self._check_available_resources()
    
    def _check_available_resources(self) -> Dict[str, List[str]]:
        """
        Verifica quais recursos est√£o dispon√≠veis no diret√≥rio de recursos.
        
        Returns:
            Dicion√°rio com os tipos de recursos dispon√≠veis
        """
        resources = {
            "text": [],
            "pdf": [],
            "video": [],
            "image": [],
            "audio": [],
            "json": []
        }
        
        # Diret√≥rio base
        base_dir = Path(os.path.abspath(os.path.join(
            os.path.dirname(__file__), 
            "..", "..", "..", ".."
        )))
        
        # Diret√≥rio de recursos processados
        processed_dir = base_dir / "processed_data"
        
        # Verifica se o diret√≥rio de textos processados existe
        text_dir = processed_dir / "text"
        if text_dir.exists():
            for file_path in text_dir.glob("*.txt"):
                resources["text"].append(str(file_path))
        
        # Verifica se o diret√≥rio de v√≠deos processados existe
        videos_dir = processed_dir / "videos"
        if videos_dir.exists():
            for file_path in videos_dir.glob("*"):
                resources["video"].append(str(file_path))
        
        # Verifica se o diret√≥rio de imagens processadas existe
        images_dir = processed_dir / "images"
        if images_dir.exists():
            for file_path in images_dir.glob("*"):
                resources["image"].append(str(file_path))
        
        # Verifica se o diret√≥rio de √°udios processados existe
        audio_dir = processed_dir / "audio"
        if audio_dir.exists():
            for file_path in audio_dir.glob("*"):
                resources["audio"].append(str(file_path))
        
        # Verifica se o diret√≥rio de transcri√ß√µes existe
        transcripts_dir = processed_dir / "transcripts"
        if transcripts_dir.exists():
            for file_path in transcripts_dir.glob("*_ocr.txt"):
                resources["image"].append(str(file_path))
        
        return resources
    
    def generate_response(
        self, 
        query: str, 
        user_level: str = "intermedi√°rio", 
        preferred_format: str = "texto",
        user_id: Optional[str] = None
    ) -> str:
        """
        Gera uma resposta adaptativa para a consulta do usu√°rio.
        
        Args:
            query: Consulta do usu√°rio
            user_level: N√≠vel de conhecimento do usu√°rio (iniciante, intermedi√°rio, avan√ßado)
            preferred_format: Formato preferido de conte√∫do (texto, v√≠deo, imagem)
            user_id: Identificador opcional do usu√°rio para armazenar intera√ß√µes
            
        Returns:
            Resposta adaptativa ao usu√°rio
        """
        # Atualiza o contexto da sess√£o para o usu√°rio
        if user_id:
            if user_id not in self.session_context:
                self.session_context[user_id] = {"last_query": "", "topics": []}
            
            # Adiciona a consulta atual ao contexto e mant√©m as √∫ltimas 3 consultas
            self.session_context[user_id]["last_query"] = query
            self.session_context[user_id]["topics"] = self._extract_topics(query)
        
        # Expande a consulta com termos relacionados
        expanded_query = self._expand_query(query)
        
        # Busca documentos relacionados √† consulta expandida
        related_docs = self.search_service.search(expanded_query, limit=5)
        
        # Se n√£o encontrar com a consulta expandida, tenta com a consulta original
        if not related_docs:
            related_docs = self.search_service.search(query, limit=5)
        
        # Verifica se foram encontrados documentos
        if not related_docs:
            # Tenta buscar em todos os recursos dispon√≠veis
            related_docs = self._search_in_all_resources(query)
            
            if not related_docs:
                # Tenta sugerir t√≥picos relacionados quando n√£o h√° resultados
                suggested_topics = self._suggest_related_topics(query)
                
                if suggested_topics:
                    response = (
                        f"N√£o sei responder exatamente sua pergunta sobre '{query}', mas aqui est√° uma prov√°vel resposta baseada nos recursos dispon√≠veis:\n\n"
                        f"Voc√™ pode estar interessado nestes t√≥picos relacionados:\n"
                    )
                    for i, topic in enumerate(suggested_topics, 1):
                        response += f"  {i}. {topic}\n"
                    response += "\nPor favor, tente reformular sua pergunta ou explorar um destes t√≥picos."
                else:
                    response = (
                        f"N√£o sei responder exatamente sua pergunta sobre '{query}', mas aqui est√° uma prov√°vel resposta baseada nos recursos dispon√≠veis:\n\n"
                        f"Por favor, tente reformular sua pergunta para que eu possa encontrar informa√ß√µes relevantes nos recursos dispon√≠veis."
                    )
            else:
                # Se encontrou documentos ap√≥s busca em todos os recursos, continua o processamento
                response = self._process_found_documents(related_docs, query, user_level, preferred_format)
        else:
            # Processa os documentos encontrados
            response = self._process_found_documents(related_docs, query, user_level, preferred_format)
        
        # Armazena a intera√ß√£o do usu√°rio, se poss√≠vel
        if user_id and self.user_progress_repository:
            self.store_user_interaction(
                user_id=user_id,
                query=query,
                response=response
            )
            
        return response
    
    def _process_found_documents(self, related_docs, query, user_level, preferred_format):
        """
        Processa os documentos encontrados para gerar uma resposta.
        
        Args:
            related_docs: Documentos encontrados
            query: Consulta do usu√°rio
            user_level: N√≠vel de conhecimento do usu√°rio
            preferred_format: Formato preferido de conte√∫do
            
        Returns:
            Resposta formatada
        """
        # Verifica a relev√¢ncia sem√¢ntica dos documentos encontrados
        relevant_docs = self._filter_by_semantic_relevance(related_docs, query)
        
        if not relevant_docs:
            # Se nenhum documento for relevante o suficiente, busca mais documentos
            more_docs = self.search_service.search(query, limit=10)
            relevant_docs = self._filter_by_semantic_relevance(more_docs, query)
        
        # Seleciona trechos relevantes dos documentos
        excerpts = self._select_relevant_excerpts(
            relevant_docs, 
            query, 
            user_level, 
            preferred_format
        )
        
        # Formata a resposta
        return self._format_response(query, excerpts, user_level, preferred_format)
    
    def _search_in_all_resources(self, query):
        """
        Busca em todos os recursos dispon√≠veis, independentemente do tipo.
        
        Args:
            query: Consulta do usu√°rio
            
        Returns:
            Lista de documentos encontrados
        """
        all_docs = []
        
        # Tenta buscar em todos os tipos de documentos com uma consulta mais ampla
        for doc_type in ["text", "pdf", "video", "image", "json"]:
            docs = self.search_service.search_by_type(query, doc_type, limit=2)
            all_docs.extend(docs)
        
        # Se ainda n√£o encontrou, tenta com palavras-chave extra√≠das da consulta
        if not all_docs:
            keywords = self._extract_topics(query)
            for keyword in keywords:
                docs = self.search_service.search(keyword, limit=2)
                all_docs.extend(docs)
                if len(all_docs) >= 3:  # Limita a 3 documentos
                    break
        
        # Remove duplicatas (baseado no ID do documento)
        unique_docs = []
        seen_ids = set()
        for doc in all_docs:
            if doc.id not in seen_ids:
                seen_ids.add(doc.id)
                unique_docs.append(doc)
        
        return unique_docs
    
    def _filter_by_semantic_relevance(
        self,
        documents: List[Document],
        query: str,
        threshold: float = 0.2  # Reduzido o threshold para capturar mais documentos
    ) -> List[Document]:
        """
        Filtra documentos por relev√¢ncia sem√¢ntica.
        
        Args:
            documents: Lista de documentos
            query: Consulta do usu√°rio
            threshold: Limiar de relev√¢ncia (0-1)
            
        Returns:
            Lista de documentos relevantes
        """
        # Extrai palavras-chave da consulta
        keywords = set(self._extract_topics(query))
        
        # Verifica cada documento
        relevant_docs = []
        for doc in documents:
            # Conta quantas palavras-chave aparecem no conte√∫do
            matches = 0
            for keyword in keywords:
                if keyword.lower() in doc.content.lower():
                    matches += 1
            
            # Calcula a relev√¢ncia
            if keywords:
                relevance = matches / len(keywords)
            else:
                relevance = 0
                
            # Adiciona o documento se for relevante
            if relevance >= threshold:
                relevant_docs.append(doc)
                
        return relevant_docs
    
    def _select_relevant_excerpts(
        self, 
        documents: List[Document],
        query: str,
        user_level: str,
        preferred_format: str
    ) -> List[Tuple[Document, str]]:
        """
        Seleciona trechos relevantes dos documentos.
        
        Args:
            documents: Lista de documentos
            query: Consulta do usu√°rio
            user_level: N√≠vel de conhecimento do usu√°rio
            preferred_format: Formato preferido de conte√∫do
            
        Returns:
            Lista de tuplas (documento, trecho relevante)
        """
        if not documents:
            return []
        
        # Extrai palavras-chave da consulta
        keywords = set(self._extract_keywords(query))
        
        # Define o tamanho do trecho com base no n√≠vel do usu√°rio
        excerpt_size = self._get_excerpt_size(user_level)
        
        # Lista para armazenar os trechos selecionados
        excerpts = []
        
        # Primeiro, prioriza documentos do formato preferido
        prioritized_docs = []
        other_docs = []
        
        for doc in documents:
            # Verifica se o arquivo existe
            source_path = self._extract_source(doc)
            if source_path and os.path.exists(source_path):
                if self._matches_preferred_format(doc, preferred_format):
                    prioritized_docs.append(doc)
                else:
                    other_docs.append(doc)
        
        # Combina as listas, com os documentos priorizados primeiro
        sorted_docs = prioritized_docs + other_docs
        
        # Limita a quantidade de documentos para n√£o sobrecarregar
        max_docs = min(5, len(sorted_docs))
        
        # Seleciona trechos dos documentos priorizados
        for doc in sorted_docs[:max_docs]:
            # Extrai um trecho relevante do conte√∫do
            excerpt = self._extract_relevant_excerpt(doc.content, keywords, excerpt_size)
            
            # Adiciona o documento e o trecho √† lista
            excerpts.append((doc, excerpt))
        
        return excerpts
    
    def _format_response(
        self, 
        query: str, 
        excerpts: List[Tuple[Document, str]],
        user_level: str,
        preferred_format: str
    ) -> str:
        """
        Formata a resposta com base nos trechos selecionados.
        
        Args:
            query: Consulta do usu√°rio
            excerpts: Lista de tuplas (documento, trecho relevante)
            user_level: N√≠vel de conhecimento do usu√°rio
            preferred_format: Formato preferido de conte√∫do
            
        Returns:
            Resposta formatada com estrutura clara, t√≥picos e destaques
        """
        if not excerpts:
            return self._generate_not_found_response(query)
        
        # Extrai palavras-chave da consulta para melhorar a busca em contexto
        search_terms = self._extract_topics(query)
        
        # Melhoria: Adicionar termos relacionados para busca mais ampla
        expanded_search_terms = set(search_terms)
        for term in search_terms:
            # Adiciona varia√ß√µes do termo para busca mais eficiente
            expanded_search_terms.add(term.lower())
            expanded_search_terms.add(term.capitalize())
            if term.lower() in self.QUERY_EXPANSION:
                expanded_search_terms.update(self.QUERY_EXPANSION[term.lower()])
            
           
            if term.lower() in ["html", "body", "head", "footer", "header", "div"]:
                expanded_search_terms.add(f"<{term}>")
                expanded_search_terms.add(f"<{term.lower()}>")
                expanded_search_terms.add(f"tag {term}")
                expanded_search_terms.add(f"elemento {term}")
        
      
        response_parts = []
        
        # Verificar qual o tipo de documento dispon√≠vel (para formatos n√£o textuais)
        has_video = any(doc.doc_type == DocumentType.VIDEO for doc, _ in excerpts)
        has_audio = any(doc.doc_type == DocumentType.AUDIO for doc, _ in excerpts)
        has_image = any(doc.doc_type == DocumentType.IMAGE for doc, _ in excerpts)
        
       
        main_title = f"‚úÖ **{query.capitalize()}:**"
        response_parts.append(main_title)
        
      
        combined_content = ""
        media_files = []
        
        # Re√∫ne todo o conte√∫do textual
        for _, excerpt in excerpts:
            if excerpt and len(excerpt.strip()) > 0:
                combined_content += excerpt.strip() + " "
        
        # Adiciona arquivos de m√≠dia encontrados
        for doc, _ in excerpts:
            file_path = self._extract_source(doc)
            if file_path and os.path.exists(file_path):
                # Registra o caminho do arquivo para incluir no final
                if doc.doc_type == DocumentType.VIDEO:
                    media_files.append((file_path, "video"))
                elif doc.doc_type == DocumentType.AUDIO:
                    media_files.append((file_path, "audio"))
                elif doc.doc_type == DocumentType.IMAGE:
                    media_files.append((file_path, "image"))
        
        # Remove poss√≠veis quebras de linha no texto para criar par√°grafos melhores
        combined_content = combined_content.replace("\n", " ").strip()
        
        # Divide o conte√∫do em par√°grafos
        paragraphs = []
        current_len = 0
        current_para = ""
        
        for sentence in combined_content.split(". "):
            if sentence:
                if current_len > 250:  # Limita par√°grafos a ~250 caracteres
                    paragraphs.append(current_para)
                    current_para = sentence + ". "
                    current_len = len(current_para)
                else:
                    current_para += sentence + ". "
                    current_len += len(sentence) + 2
        
        if current_para:
            paragraphs.append(current_para)
        
        # Adiciona os par√°grafos √† resposta
        for para in paragraphs:
            response_parts.append(para)
            response_parts.append("")  # Linha em branco entre par√°grafos
        
        # Adiciona os arquivos de m√≠dia no formato especial que o frontend pode detectar
        if media_files:
            if has_video:
                video_paths = [path for path, type in media_files if type == "video"]
                if video_paths:
                    response_parts.append("<!-- file_path: " + video_paths[0] + " -->")
                    response_parts.append("üì∫ **Assista ao v√≠deo sobre este tema para visualizar melhor o conte√∫do.**")
                    response_parts.append("")
            
            if has_audio:
                audio_paths = [path for path, type in media_files if type == "audio"]
                if audio_paths:
                    response_parts.append("<!-- file_path: " + audio_paths[0] + " -->")
                    response_parts.append("üîä **Ou√ßa a explica√ß√£o em √°udio para entender melhor o tema.**")
                    response_parts.append("")
            
            if has_image:
                image_paths = [path for path, type in media_files if type == "image"]
                if image_paths:
                    response_parts.append("<!-- file_path: " + image_paths[0] + " -->")
                    response_parts.append("üñºÔ∏è **Veja a imagem relacionada a este tema para melhor compreens√£o.**")
                    response_parts.append("")
        
        # Adicionar fontes usadas (de forma mais sutil)
        response_parts.append("üìö **Fontes consultadas:**")
        
        # Adicionar fontes usadas
        unique_docs = {}
        for doc, _ in excerpts:
            if doc.id not in unique_docs:
                unique_docs[doc.id] = doc
                
        for i, doc in enumerate(unique_docs.values(), 1):
            doc_type = self._get_document_type_name(doc.doc_type)
            doc_name = self._extract_title(doc)
            response_parts.append(f"{i}. {doc_type}: {doc_name}")
        
        # Adicionar dica para o usu√°rio aprofundar o conte√∫do
        response_parts.append("\nüßê **Posso aprofundar algum ponto espec√≠fico sobre este tema?**")
        
        # Juntar todas as partes
        response = "\n".join(response_parts)
        
        return response
    
    def _perform_deep_search(self, query: str, preferred_format: str) -> str:
        """
        Realiza uma busca mais profunda nos documentos quando a busca normal n√£o encontra resultados espec√≠ficos.
        
        Args:
            query: Consulta original do usu√°rio
            preferred_format: Formato preferido de conte√∫do
            
        Returns:
            String com conte√∫do adicional encontrado na busca profunda
        """
        # Extrai termos para busca profunda
        search_terms = set(self._extract_topics(query))
        
        # Adiciona varia√ß√µes importantes para HTML e tags
        if any(term.lower() in ["html", "body", "head", "tag", "elemento"] for term in search_terms):
            search_terms.update(["tag", "elemento", "html5", "estrutura", "documento"])
            # Para termos espec√≠ficos de tags HTML
            for term in list(search_terms):
                if term.lower() in ["body", "head", "header", "footer", "section"]:
                    search_terms.add(f"<{term}>")
                    search_terms.add(f"tag {term}")
        
        # Monta uma consulta expandida para busca
        expanded_query = " OR ".join(search_terms)
        
        # Realiza a busca aprofundada no reposit√≥rio
        docs = self.search_service.search(expanded_query, limit=10)
        
        # Filtra por relev√¢ncia e extrai trechos importantes
        results = []
        for doc in docs:
            # Busca por men√ß√µes dos termos espec√≠ficos no conte√∫do
            content = doc.content.lower()
            
            # Para cada termo de busca, encontra o contexto ao redor
            for term in search_terms:
                term_lower = term.lower()
                # Ignora termos muito curtos
                if len(term_lower) < 3:
                    continue
                    
                # Localiza posi√ß√µes do termo no conte√∫do
                pos = content.find(term_lower)
                if pos >= 0:
                    # Extrai o contexto (at√© 200 caracteres)
                    start = max(0, pos - 100)
                    end = min(len(content), pos + 100)
                    
                    # Ajusta para n√£o cortar palavras
                    while start > 0 and content[start] != ' ':
                        start -= 1
                    while end < len(content) and content[end] != ' ':
                        end += 1
                    
                    # Extrai o contexto e formata
                    context = content[start:end].strip()
                    # Capitaliza a primeira letra
                    if context:
                        context = context[0].upper() + context[1:]
                    
                    # Verifica se j√° existe um resultado similar para evitar duplica√ß√µes
                    is_duplicate = False
                    for existing in results:
                        if self._calculate_similarity(context, existing["context"]) > 0.7:
                            is_duplicate = True
                            break
                    
                    if not is_duplicate:
                        results.append({
                            "term": term,
                            "context": context,
                            "doc_type": doc.doc_type,
                            "doc_id": doc.id
                        })
        
        # Se n√£o encontrou resultados adicionais, retorna string vazia
        if not results:
            return ""
        
        # Formata os resultados
        formatted_results = []
        for i, result in enumerate(results[:3], 1):  # Limita a 3 resultados para n√£o sobrecarregar
            doc_type = self._get_document_type_name(result["doc_type"])
            context = result["context"]
            formatted_results.append(f"{i}. {context}\n   (Fonte: {doc_type})")
        
        return "\n".join(formatted_results)
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """
        Calcula uma m√©trica simples de similaridade entre dois textos.
        
        Args:
            text1: Primeiro texto
            text2: Segundo texto
            
        Returns:
            Valor entre 0 e 1 representando a similaridade
        """
        # Implementa√ß√£o simples usando Jaccard similarity
        if not text1 or not text2:
            return 0.0
            
        # Tokeniza em palavras
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        # Calcula a similaridade
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        if union == 0:
            return 0.0
            
        return intersection / union
    
    def _get_document_type_name(self, doc_type: DocumentType) -> str:
        """
        Retorna o nome amig√°vel do tipo de documento.
        
        Args:
            doc_type: Tipo de documento
            
        Returns:
            Nome amig√°vel do tipo de documento
        """
        type_names = {
            DocumentType.TEXT: "Texto",
            DocumentType.PDF: "Pdf",
            DocumentType.VIDEO: "V√≠deo",
            DocumentType.IMAGE: "Imagem",
            DocumentType.JSON: "Json"
        }
        return type_names.get(doc_type, "Documento")
    
    def _extract_title(self, document: Document) -> str:
        """
        Extrai o t√≠tulo de um documento.
        
        Args:
            document: Documento
            
        Returns:
            T√≠tulo do documento ou ID se n√£o encontrado
        """
        # Tentar extrair do metadata
        if document.metadata:
            if "title" in document.metadata:
                return document.metadata["title"]
            elif "source" in document.metadata:
                # Extrai o nome do arquivo da fonte
                filename = os.path.basename(document.metadata["source"])
                return filename
                
        # Para documentos JSON, tenta extrair o nome ou t√≠tulo do conte√∫do
        if document.doc_type == DocumentType.JSON:
            name_match = re.search(r'name:\s+([^,\n]+)', document.content)
            title_match = re.search(r'title:\s+([^,\n]+)', document.content)
            
            if name_match:
                return name_match.group(1).strip()
            elif title_match:
                return title_match.group(1).strip()
        
        # Usar as primeiras palavras do conte√∫do como t√≠tulo
        words = document.content.split()
        if len(words) > 5:
            return " ".join(words[:5]) + "..."
        else:
            return document.id
    
    def _extract_preview(self, content: str, max_length: int = 100) -> str:
        """
        Extrai uma pr√©via do conte√∫do.
        
        Args:
            content: Conte√∫do do documento
            max_length: Tamanho m√°ximo da pr√©via
            
        Returns:
            Pr√©via do conte√∫do
        """
        if len(content) <= max_length:
            return content
        return content[:max_length] + "..."
    
    def _extract_source(self, document: Document) -> str:
        """
        Extrai a fonte de um documento.
        
        Args:
            document: Documento
            
        Returns:
            Fonte do documento ou vazio se n√£o encontrada
        """
        if document.metadata and "source" in document.metadata:
            source_path = document.metadata["source"]
            
            # Verifica se o caminho existe
            if os.path.exists(source_path):
                return source_path
            
            # Se n√£o existir, tenta encontrar um caminho correspondente na estrutura de diret√≥rios processados
            file_name = os.path.basename(source_path)
            
            # Mapeia o tipo de documento para o diret√≥rio correspondente
            dir_mapping = {
                DocumentType.TEXT: "text",
                DocumentType.PDF: "text",  # PDFs processados s√£o armazenados como texto
                DocumentType.VIDEO: "videos",
                DocumentType.IMAGE: "images",
                DocumentType.AUDIO: "audio",
                DocumentType.JSON: "text"  # JSONs processados s√£o armazenados como texto
            }
            
            if document.doc_type in dir_mapping:
                subdir = dir_mapping[document.doc_type]
                corrected_path = os.path.join(str(self.resources_dir), subdir, file_name)
                
                if os.path.exists(corrected_path):
                    return corrected_path
            
            # Se ainda n√£o encontrou, retorna o caminho do diret√≥rio processed_data
            return str(self.resources_dir)
            
        return ""
    
    def _extract_keywords(self, query: str) -> List[str]:
        """
        Extrai palavras-chave de uma consulta.
        
        Args:
            query: Consulta do usu√°rio
            
        Returns:
            Lista de palavras-chave
        """
        # Remover pontua√ß√£o e dividir em palavras
        words = re.findall(r'\b\w+\b', query.lower())
        
        # Remover stop words simples em portugu√™s
        stop_words = {
            "a", "o", "e", "de", "da", "do", "em", "um", "uma", "que", "√©",
            "para", "com", "por", "como", "mas", "se", "no", "na", "os", "as",
            "me", "explique", "sobre", "quais", "s√£o", "como", "funciona",
            "quem", "onde", "quando", "tem", "ter", "h√°", "esse", "essa",
            "isto", "isso", "aquilo", "este", "esta", "meu", "minha", "seu", "sua"
        }
        
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        return keywords
    
    def _matches_preferred_format(self, document: Document, preferred_format: str) -> bool:
        """
        Verifica se o documento corresponde ao formato preferido.
        
        Args:
            document: Documento
            preferred_format: Formato preferido
            
        Returns:
            True se corresponder, False caso contr√°rio
        """
        # Mapeamento de formatos para tipos de documento
        format_mapping = {
            "texto": [DocumentType.TEXT, DocumentType.PDF, DocumentType.JSON],
            "v√≠deo": [DocumentType.VIDEO],
            "video": [DocumentType.VIDEO],
            "imagem": [DocumentType.IMAGE],
            "image": [DocumentType.IMAGE],
            "√°udio": [DocumentType.AUDIO],
            "audio": [DocumentType.AUDIO]
        }
        
        # Normaliza o formato preferido
        preferred_format_lower = preferred_format.lower()
        
        # Verifica se o formato est√° no mapeamento
        if preferred_format_lower in format_mapping:
            return document.doc_type in format_mapping[preferred_format_lower]
        
        # Se o formato n√£o for reconhecido, assume texto como padr√£o
        return document.doc_type in [DocumentType.TEXT, DocumentType.PDF, DocumentType.JSON]
    
    def _get_excerpt_size(self, user_level: str) -> int:
        """
        Define o tamanho do trecho com base no n√≠vel do usu√°rio.
        
        Args:
            user_level: N√≠vel de conhecimento do usu√°rio
            
        Returns:
            Tamanho do trecho em caracteres
        """
        if user_level == "iniciante":
            return 200  # Trechos curtos para iniciantes
        elif user_level == "intermedi√°rio":
            return 400  # Trechos m√©dios para n√≠vel intermedi√°rio
        else:  # avan√ßado
            return 800  # Trechos maiores para usu√°rios avan√ßados
    
    def _extract_relevant_excerpt(
        self, 
        content: str, 
        keywords: Set[str],
        max_length: int
    ) -> str:
        """
        Extrai um trecho relevante do conte√∫do.
        
        Args:
            content: Conte√∫do do documento
            keywords: Palavras-chave da consulta
            max_length: Tamanho m√°ximo do trecho
            
        Returns:
            Trecho relevante
        """
        # Se o conte√∫do for pequeno, retorna completo
        if len(content) <= max_length:
            return content
        
        # Divide o conte√∫do em par√°grafos
        paragraphs = content.split('\n\n')
        
        # Se houver apenas um par√°grafo, retorna os primeiros caracteres
        if len(paragraphs) <= 1:
            return content[:max_length]
        
        # Calcula a relev√¢ncia de cada par√°grafo
        paragraph_scores = []
        for p in paragraphs:
            score = 0
            for keyword in keywords:
                if keyword.lower() in p.lower():
                    score += 1
            paragraph_scores.append((p, score))
        
        # Ordena os par√°grafos por relev√¢ncia
        paragraph_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Seleciona os par√°grafos mais relevantes
        selected_paragraphs = []
        current_length = 0
        
        for p, _ in paragraph_scores:
            # Se adicionar o par√°grafo ultrapassar o tamanho m√°ximo, para
            if current_length + len(p) > max_length:
                # Se n√£o temos nenhum par√°grafo ainda, pega um trecho do primeiro
                if not selected_paragraphs:
                    return paragraph_scores[0][0][:max_length]
                break
                
            selected_paragraphs.append(p)
            current_length += len(p) + 2  # +2 para "\n\n"
            
        # Junta os par√°grafos selecionados
        return "\n\n".join(selected_paragraphs)
    
    def analyze_user_learning_patterns(self, user_id: str) -> Dict[str, Any]:
        """
        Analisa o hist√≥rico de intera√ß√µes do usu√°rio para identificar padr√µes de aprendizagem.
        
        Args:
            user_id: ID do usu√°rio
            
        Returns:
            Dicion√°rio com an√°lise de padr√µes e recomenda√ß√µes
        """
        user_progress = self.user_progress_repository.get_by_id(user_id)
        if not user_progress or not user_progress.interactions:
            return {"status": "insufficient_data"}
        
        # An√°lise de intera√ß√µes recentes (√∫ltimas 10)
        recent_interactions = user_progress.get_recent_interactions(10)
        
        # Extrai t√≥picos das consultas recentes
        topics_frequency = {}
        for interaction in recent_interactions:
            topics = self._extract_topics(interaction.query)
            for topic in topics:
                topics_frequency[topic] = topics_frequency.get(topic, 0) + 1
        
        # Identifica t√≥picos mais frequentes
        frequent_topics = sorted(
            topics_frequency.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:3]
        
        # Analisa dificuldades com base no feedback
        difficulty_topics = []
        for interaction in recent_interactions:
            if interaction.feedback and "negativ" in interaction.feedback.lower():
                topics = self._extract_topics(interaction.query)
                difficulty_topics.extend(topics)
        
        # Identifica o formato preferido com base nas intera√ß√µes
        preferred_format = self._infer_learning_style(recent_interactions)
        
        return {
            "status": "success",
            "frequent_topics": [topic for topic, _ in frequent_topics],
            "difficulty_topics": list(set(difficulty_topics)),
            "learning_style": preferred_format or user_progress.profile.preferred_format,
            "recommendations": self._generate_learning_recommendations(
                frequent_topics, 
                difficulty_topics, 
                user_progress.profile.level
            )
        }
    
    def _infer_learning_style(self, interactions: List[UserInteraction]) -> Optional[str]:
        """
        Infere o estilo de aprendizagem com base nas intera√ß√µes.
        
        Args:
            interactions: Lista de intera√ß√µes do usu√°rio
            
        Returns:
            Estilo de aprendizagem inferido ou None
        """
        # Implementa√ß√£o simples: analisa prefer√™ncia por tipo de conte√∫do
        content_preference = {"texto": 0, "v√≠deo": 0, "imagem": 0}
        
        for interaction in interactions:
            # Analisa a consulta por men√ß√µes a formatos
            query = interaction.query.lower()
            if "v√≠deo" in query or "video" in query or "assistir" in query or "ver" in query:
                content_preference["v√≠deo"] += 1
            elif "imagem" in query or "figura" in query or "visual" in query or "diagrama" in query:
                content_preference["imagem"] += 1
            else:
                content_preference["texto"] += 1
        
        # Determina se h√° uma prefer√™ncia clara
        # (pelo menos 50% mais que a m√©dia dos outros)
        max_preference = max(content_preference.items(), key=lambda x: x[1])
        values = list(content_preference.values())
        avg_others = (sum(values) - max_preference[1]) / (len(values) - 1) if len(values) > 1 else 0
        
        if max_preference[1] > 0 and max_preference[1] >= avg_others * 1.5:
            return max_preference[0]
        
        return None
    
    def _generate_learning_recommendations(
        self,
        frequent_topics: List[Tuple[str, int]],
        difficulty_topics: List[str],
        user_level: str
    ) -> List[Dict[str, Any]]:
        """
        Gera recomenda√ß√µes de aprendizado com base nos padr√µes detectados.
        
        Args:
            frequent_topics: Lista de t√≥picos frequentes com contagem
            difficulty_topics: Lista de t√≥picos com dificuldades
            user_level: N√≠vel de conhecimento do usu√°rio
            
        Returns:
            Lista de recomenda√ß√µes
        """
        recommendations = []
        
        # Adiciona recomenda√ß√µes para t√≥picos com dificuldade
        if difficulty_topics:
            # Reduz o n√≠vel para t√≥picos dif√≠ceis
            effective_level = "iniciante" if user_level != "iniciante" else "iniciante"
            
            # Busca conte√∫dos mais simples para os t√≥picos dif√≠ceis
            for topic in difficulty_topics[:2]:  # Limita a 2 t√≥picos dif√≠ceis
                query = f"entender {topic} explica√ß√£o simples"
                topic_suggestions = self.suggest_related_content(
                    query=query,
                    user_level=effective_level,
                    limit=1
                )
                
                if topic_suggestions:
                    for suggestion in topic_suggestions:
                        suggestion["reason"] = f"Para ajudar com dificuldades sobre {topic}"
                        recommendations.append(suggestion)
        
        # Adiciona recomenda√ß√µes para aprofundar nos t√≥picos frequentes
        if frequent_topics:
            # Aumenta o n√≠vel para t√≥picos frequentes (se n√£o for avan√ßado)
            effective_level = "avan√ßado" if user_level != "avan√ßado" else "avan√ßado"
            
            # Busca conte√∫dos mais avan√ßados para os t√≥picos frequentes
            for topic, _ in frequent_topics[:2]:  # Limita a 2 t√≥picos frequentes
                query = f"{topic} avan√ßado conceitos aprofundados"
                topic_suggestions = self.suggest_related_content(
                    query=query,
                    user_level=effective_level,
                    limit=1
                )
                
                if topic_suggestions:
                    for suggestion in topic_suggestions:
                        suggestion["reason"] = f"Para aprofundar seus conhecimentos em {topic}"
                        recommendations.append(suggestion)
        
        # Adiciona recomenda√ß√£o para t√≥picos relacionados
        if frequent_topics:
            # Extrai palavras-chave dos t√≥picos frequentes
            topic_words = [topic for topic, _ in frequent_topics]
            related_query = " ".join([t for t in topic_words if t])
            
            if related_query:
                # Busca t√≥picos relacionados
                related_suggestions = self.suggest_related_content(
                    query=f"{related_query} t√≥picos relacionados",
                    user_level=user_level,
                    limit=2
                )
                
                if related_suggestions:
                    for suggestion in related_suggestions:
                        suggestion["reason"] = "Conte√∫do relacionado aos seus interesses"
                        recommendations.append(suggestion)
        
        return recommendations[:5]  # Limita a 5 recomenda√ß√µes no total
    
    def suggest_proactive_content(self, user_id: str) -> List[Dict[str, Any]]:
        """
        Sugere conte√∫dos proativamente com base no hist√≥rico do usu√°rio.
        
        Args:
            user_id: ID do usu√°rio
            
        Returns:
            Lista de conte√∫dos sugeridos
        """
        # Analisa padr√µes de aprendizagem
        patterns = self.analyze_user_learning_patterns(user_id)
        
        if patterns["status"] == "insufficient_data":
            # Se n√£o h√° dados suficientes, retorna recomenda√ß√µes gen√©ricas
            return self.suggest_related_content("aprendizagem adaptativa", limit=3)
        
        # Se j√° temos recomenda√ß√µes baseadas em padr√µes, usa-as
        if "recommendations" in patterns and patterns["recommendations"]:
            return patterns["recommendations"]
        
        # Caso contr√°rio, combina t√≥picos frequentes e t√≥picos com dificuldade para gerar sugest√µes
        all_topics = patterns.get("frequent_topics", []) + patterns.get("difficulty_topics", [])
        
        # Remove duplicatas mantendo a ordem
        unique_topics = []
        for topic in all_topics:
            if topic not in unique_topics:
                unique_topics.append(topic)
        
        # Limita a 3 t√≥picos para busca
        search_topics = unique_topics[:3]
        
        # Se n√£o houver t√≥picos suficientes, usa um termo gen√©rico
        if not search_topics:
            search_topics = ["aprendizagem", "educa√ß√£o", "tecnologia"]
        
        # Prepara a consulta combinada
        combined_query = " ".join(search_topics)
        
        # Busca conte√∫dos relacionados aos t√≥picos
        results = self.suggest_related_content(
            combined_query, 
            user_level=patterns.get("learning_style", "intermedi√°rio"),
            limit=5
        )
        
        # Adiciona a raz√£o da recomenda√ß√£o
        for item in results:
            item["reason"] = "Baseado em seus interesses recentes"
            
        return results
    
    def _expand_query(self, query: str) -> str:
        """
        Expande a consulta com termos relacionados.
        
        Args:
            query: Consulta original
            
        Returns:
            Consulta expandida
        """
        # Tokeniza√ß√£o simples
        query_lower = query.lower()
        
        # Verifica se algum termo da consulta est√° no dicion√°rio de expans√£o
        for term, expansions in self.QUERY_EXPANSION.items():
            if term.lower() in query_lower:
                # Adiciona at√© 2 termos de expans√£o √† consulta original
                for expansion in expansions[:2]:
                    if expansion.lower() not in query_lower:
                        query += f" {expansion}"
                break
                
        return query
    
    def _extract_topics(self, text: str) -> List[str]:
        """
        Extrai t√≥picos relevantes de um texto.
        
        Args:
            text: Texto para extra√ß√£o de t√≥picos
            
        Returns:
            Lista de t√≥picos extra√≠dos
        """
        # Tokeniza o texto
        words = re.findall(r'\b\w+\b', text.lower())
        
        # Lista de palavras irrelevantes (stopwords) em portugu√™s
        stop_words = {
            "o", "a", "os", "as", "um", "uma", "uns", "umas", "de", "do", "da", "dos", 
            "das", "no", "na", "nos", "nas", "ao", "aos", "√†", "√†s", "pelo", "pela", 
            "pelos", "pelas", "em", "por", "para", "com", "sem", "sob", "sobre", 
            "entre", "que", "quem", "qual", "quando", "onde", "como", "porque",
            "e", "ou", "mas", "por√©m", "entretanto", "contudo", "todavia", "se", 
            "caso", "pois", "logo", "assim", "portanto", "ent√£o", "por isso",
            "isto", "isso", "aquilo", "este", "esta", "meu", "minha", "seu", "sua"
        }
        
        # Filtra palavras irrelevantes e curtas
        topics = [word for word in words if word not in stop_words and len(word) > 2]
        
        # Remove duplicatas mantendo a ordem
        unique_topics = []
        for topic in topics:
            if topic not in unique_topics:
                unique_topics.append(topic)
                
        return unique_topics
    
    def _suggest_related_topics(self, query: str) -> List[str]:
        """
        Sugere t√≥picos relacionados √† consulta.
        
        Args:
            query: Consulta do usu√°rio
            
        Returns:
            Lista de t√≥picos relacionados
        """
        # Mapeamento de t√≥picos para sugest√µes relacionadas
        related_topics_map = {
            "html": ["Estrutura b√°sica HTML5", "Tags sem√¢nticas", "Formul√°rios HTML5", "Links e √¢ncoras", "Tabelas HTML"],
            "css": ["Seletores CSS", "Box model", "Flexbox", "Grid layout", "Responsividade"],
            "javascript": ["Vari√°veis e tipos", "Fun√ß√µes", "DOM", "Eventos", "Promises"],
            "web": ["HTML5", "CSS3", "JavaScript", "Responsividade", "Acessibilidade"],
            "p√°gina": ["Estrutura HTML", "Cabe√ßalho e rodap√©", "Navega√ß√£o", "Conte√∫do principal", "Se√ß√µes"],
            "estrutura": ["DOCTYPE", "HTML", "Head", "Body", "Elementos sem√¢nticos"],
            "tabela": ["Table", "TR", "TD", "TH", "Caption"],
            "lista": ["UL", "OL", "LI", "DL", "Listas aninhadas"],
            "formul√°rio": ["Form", "Input", "Select", "Textarea", "Button"],
            "texto": ["Headings", "Par√°grafos", "Formata√ß√£o", "Cita√ß√µes", "C√≥digo"]
        }
        
        # Extrai t√≥picos da consulta
        topics = self._extract_topics(query)
        
        # Coleta sugest√µes para os t√≥picos identificados
        suggestions = []
        for topic in topics:
            for key, values in related_topics_map.items():
                if topic in key or key in topic:
                    suggestions.extend(values)
                    break
        
        # Se n√£o encontrou sugest√µes espec√≠ficas, usa sugest√µes gerais de HTML
        if not suggestions:
            suggestions = [
                "Estrutura b√°sica HTML5",
                "Tags sem√¢nticas HTML5",
                "Formata√ß√£o de texto em HTML",
                "Listas e tabelas em HTML",
                "Formul√°rios HTML5"
            ]
        
        # Remove duplicatas mantendo a ordem
        unique_suggestions = []
        for suggestion in suggestions:
            if suggestion not in unique_suggestions:
                unique_suggestions.append(suggestion)
                
        return unique_suggestions[:5]  # Retorna at√© 5 sugest√µes
    
    def suggest_related_content(
        self, 
        query: str, 
        user_level: str = "intermedi√°rio", 
        limit: int = 3
    ) -> List[Dict[str, Any]]:
        """
        Sugere conte√∫dos relacionados √† consulta do usu√°rio.
        
        Args:
            query: Consulta do usu√°rio
            user_level: N√≠vel de conhecimento do usu√°rio
            limit: N√∫mero m√°ximo de sugest√µes
            
        Returns:
            Lista de dicion√°rios com informa√ß√µes sobre os conte√∫dos relacionados
        """
        # Expande a consulta para melhorar os resultados
        expanded_query = self._expand_query(query)
        
        # Busca documentos relacionados
        related_docs = self.search_service.search(expanded_query, limit=limit+2)  # Busca alguns a mais para ter variedade
        
        # Se n√£o encontrar com a consulta expandida, tenta com a consulta original
        if not related_docs:
            related_docs = self.search_service.search(query, limit=limit+2)
        
        # Se ainda n√£o encontrou, tenta com t√≥picos relacionados
        if not related_docs:
            topics = self._suggest_related_topics(query)
            for topic in topics:
                docs = self.search_service.search(topic, limit=2)
                related_docs.extend(docs)
                if len(related_docs) >= limit+2:
                    break
        
        # Converte os documentos em conte√∫dos relacionados
        related_content = []
        seen_titles = set()  # Para evitar conte√∫dos duplicados
        
        for doc in related_docs:
            # Extrai o t√≠tulo do documento
            title = self._extract_title(doc)
            
            # Evita duplica√ß√µes
            if title in seen_titles:
                continue
                
            seen_titles.add(title)
            
            # Obt√©m o caminho correto do arquivo
            source_path = self._extract_source(doc)
            
            # Verifica se o arquivo existe (n√£o usa arquivos de amostra)
            if source_path and os.path.exists(source_path):
                # Cria o item de conte√∫do relacionado
                content_item = {
                    "id": doc.id,
                    "title": title,
                    "type": doc.doc_type.value,
                    "preview": self._extract_preview(doc.content),
                    "source": source_path
                }
                
                related_content.append(content_item)
                
                # Limita ao n√∫mero solicitado
                if len(related_content) >= limit:
                    break
                    
        return related_content
    
    def _generate_not_found_response(self, query: str) -> str:
        """
        Gera uma resposta quando n√£o s√£o encontrados documentos relevantes.
        
        Args:
            query: Consulta do usu√°rio
            
        Returns:
            Resposta formatada
        """
        return (
            f"N√£o sei responder exatamente sua pergunta, mas aqui est√° uma prov√°vel resposta com base nos recursos dispon√≠veis:\n\n"
            f"Infelizmente, n√£o encontrei informa√ß√µes espec√≠ficas sobre este t√≥pico nos recursos dispon√≠veis. Tente outra pergunta."
        )
    
    def store_user_interaction(
        self, 
        user_id: str, 
        query: str, 
        response: str, 
        feedback: Optional[str] = None
    ) -> bool:
        """
        Armazena a intera√ß√£o do usu√°rio para uso futuro.
        
        Args:
            user_id: ID do usu√°rio
            query: Consulta do usu√°rio
            response: Resposta fornecida
            feedback: Feedback opcional do usu√°rio
            
        Returns:
            True se armazenado com sucesso, False caso contr√°rio
        """
        if not self.user_progress_repository:
            return False
            
        return self.user_progress_repository.update_interaction(
            user_id=user_id,
            query=query,
            response=response,
            feedback=feedback
        ) 